import streamlit as st
from langchain_community.llms import Cohere
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

from dotenv import load_dotenv
import os

load_dotenv()
os.environ["COHERE_API_KEY"] = os.getenv("COHERE_API_KEY")


# ðŸ”§ Streamlit app title
st.title("Chatbot with LangChain and Cohere")

# ðŸ”§ Input field
question = st.text_input("Ask a question:")

# ðŸ”§ Define prompt template
Prompt = ChatPromptTemplate.from_messages(
    [("system", "You are a helpful assistant."),
     ("user", "Question: {question}")]
)

# ðŸ”§ Initialize Cohere LLM via LangChain
llm = Cohere(model="command-r")  # or another Cohere model if desired

# ðŸ”§ Output parser for clean string outputs
output_parser = StrOutputParser()

# ðŸ”§ Create the chain
chain = Prompt | llm | output_parser

# ðŸ”§ Run the chain if user inputs a question
if question:
    response = chain.invoke({"question": question})
    st.write(response)
